{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65655b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('/Users/erica/Desktop/Y3S2/DSE3101/Local/reslae_price_normalized_for_ML.csv')\n",
    "\n",
    "df = df.drop(columns=['flat_model', 'building_age_2025', 'total_unemployment_rate', \n",
    "                      'Chinese', 'Malays', 'Indians', 'Others', 'fx_rate', 'floor_area_sqm'])\n",
    "df_normalized_clean = df.copy()\n",
    "def normalize(col):\n",
    "    return (col - col.min()) / (col.max() - col.min()) if col.max() != col.min() else col\n",
    "\n",
    "df_normalized_clean['month'] = pd.to_datetime(df_normalized_clean['month'])\n",
    "df_normalized_clean['year'] = df_normalized_clean['month'].dt.year.astype(float)\n",
    "df_normalized_clean['month_num'] = df_normalized_clean['month'].dt.month.astype(float)\n",
    "df_normalized_clean = df_normalized_clean.drop(columns=['month'])\n",
    "df_normalized_clean = df_normalized_clean.drop(columns = ['CPI (base 2024-12)'])\n",
    "\n",
    "columns_to_normalize = ['inflation_rate (x100)', 'interest_rate', 'priv_prop',\n",
    "                        'resident_unemployment_rate', 'month_num', 'year']\n",
    "\n",
    "df_normalized_clean[columns_to_normalize] = df_normalized_clean[columns_to_normalize].apply(normalize)\n",
    "\n",
    "categorical_features = ['town']\n",
    "numerical_features = [\n",
    "    'storey_range', 'remaining_lease',\n",
    "    'lat', 'lon', 'nearest_mrt_distance', 'nearest_bus_distance',\n",
    "    'education_score', 'shopping_score', 'food_score', 'recreation_score',\n",
    "    'healthcare_score', 'inflation_rate (x100)',\n",
    "    'resident_unemployment_rate',\n",
    "    'interest_rate', 'avg_household_income', 'priv_prop', 'flat_type'\n",
    "]\n",
    "numerical_features.extend(['year', 'month_num'])\n",
    "demographic_features = [\n",
    "    'NoReligion', 'Buddhism', 'Taoism1', 'Islam', 'Hinduism', 'Sikhism',\n",
    "    'Christianity_Catholic', 'Christianity_OtherChristians', 'OtherReligions'\n",
    "]\n",
    "numerical_features.extend(demographic_features)  # Add to numerical pipeline\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "757b07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_normalized_clean.sample(frac=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "831ee1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  15.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  15.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  15.1s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  15.1s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  15.2s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  15.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  30.1s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  30.2s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  15.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  30.4s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  15.5s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  15.6s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  30.7s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  30.8s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  30.9s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  31.2s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  31.3s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  31.3s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  25.0s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  25.1s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  25.2s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  24.5s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  24.3s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  25.7s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  53.0s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  53.1s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.5s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  56.6s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.0s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  53.2s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.7s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  53.8s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  56.6s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  51.4s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  31.7s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  30.9s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  31.6s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  51.5s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  51.9s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  27.7s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  27.6s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  27.6s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time= 1.0min\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time= 1.0min\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.1s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.4s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time= 1.0min\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.2s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  54.2s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  54.3s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  52.9s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  44.6s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  43.1s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  42.8s\n",
      "Best parameters: {'regressor__max_depth': 30, 'regressor__min_samples_leaf': 1, 'regressor__n_estimators': 200}\n",
      "Best CV MAE: 0.021066403486549257\n",
      "Best CV RMSE: 0.030548845863865737\n",
      "Best CV R2: 0.9442009325741738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200],\n",
    "    'regressor__max_depth': [10, 20, 30],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring={\n",
    "        'MAE': 'neg_mean_absolute_error',\n",
    "        'RMSE': 'neg_root_mean_squared_error',\n",
    "        'R2': 'r2'\n",
    "    },\n",
    "    refit='MAE',  # Use MAE to choose the best model\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Split your data\n",
    "X = df_sample.drop(columns=['resale_price'])\n",
    "y = df_sample['resale_price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV MAE:\", -grid_search.cv_results_['mean_test_MAE'][grid_search.best_index_])\n",
    "print(\"Best CV RMSE:\", -grid_search.cv_results_['mean_test_RMSE'][grid_search.best_index_])\n",
    "print(\"Best CV R2:\", grid_search.cv_results_['mean_test_R2'][grid_search.best_index_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c01ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(\n",
    "        max_depth=30,\n",
    "        min_samples_leaf=1,\n",
    "        n_estimators=200,\n",
    "        random_state=42\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34053e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_resale_price_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "X_full = df_normalized_clean.drop(columns=['resale_price'])\n",
    "y_full = df_normalized_clean['resale_price']\n",
    "best_model.fit(X_full, y_full)\n",
    "joblib.dump(best_model, 'best_resale_price_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bac3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
