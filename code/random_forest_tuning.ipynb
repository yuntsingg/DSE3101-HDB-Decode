{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65655b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('/Users/erica/Desktop/Y3S2/DSE3101/Local/reslae_price_normalized_for_ML.csv')\n",
    "\n",
    "df = df.drop(columns=['flat_model', 'building_age_2025', 'total_unemployment_rate', \n",
    "                      'Chinese', 'Malays', 'Indians', 'Others', 'fx_rate', 'floor_area_sqm'])\n",
    "df_normalized_clean = df.copy()\n",
    "def normalize(col):\n",
    "    return (col - col.min()) / (col.max() - col.min()) if col.max() != col.min() else col\n",
    "\n",
    "df_normalized_clean['month'] = pd.to_datetime(df_normalized_clean['month'])\n",
    "df_normalized_clean['year'] = df_normalized_clean['month'].dt.year.astype(float)\n",
    "df_normalized_clean['month_num'] = df_normalized_clean['month'].dt.month.astype(float)\n",
    "df_normalized_clean = df_normalized_clean.drop(columns=['month'])\n",
    "df_normalized_clean = df_normalized_clean.drop(columns = ['CPI (base 2024-12)'])\n",
    "\n",
    "columns_to_normalize = ['inflation_rate (x100)', 'interest_rate', 'priv_prop',\n",
    "                        'resident_unemployment_rate', 'month_num', 'year']\n",
    "\n",
    "df_normalized_clean[columns_to_normalize] = df_normalized_clean[columns_to_normalize].apply(normalize)\n",
    "\n",
    "categorical_features = ['town']\n",
    "numerical_features = [\n",
    "    'storey_range', 'remaining_lease',\n",
    "    'lat', 'lon', 'nearest_mrt_distance', 'nearest_bus_distance',\n",
    "    'education_score', 'shopping_score', 'food_score', 'recreation_score',\n",
    "    'healthcare_score', 'inflation_rate (x100)',\n",
    "    'resident_unemployment_rate',\n",
    "    'interest_rate', 'avg_household_income', 'priv_prop', 'flat_type'\n",
    "]\n",
    "numerical_features.extend(['year', 'month_num'])\n",
    "demographic_features = [\n",
    "    'NoReligion', 'Buddhism', 'Taoism1', 'Islam', 'Hinduism', 'Sikhism',\n",
    "    'Christianity_Catholic', 'Christianity_OtherChristians', 'OtherReligions'\n",
    "]\n",
    "numerical_features.extend(demographic_features)  # Add to numerical pipeline\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757b07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_normalized_clean.sample(frac=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "831ee1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  15.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  15.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  15.1s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  15.1s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  15.2s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  15.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  30.1s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  30.2s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  15.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  30.4s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  15.5s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  15.6s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  30.7s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  30.8s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  30.9s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  31.2s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  31.3s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  31.3s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  25.0s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  25.1s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  25.2s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  24.5s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  24.3s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  25.7s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  53.0s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  53.1s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.5s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=  56.6s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.0s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  53.2s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.7s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  53.8s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  56.6s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  51.4s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  31.7s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  30.9s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=  31.6s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  51.5s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  51.9s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  27.7s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  27.6s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=  27.6s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time= 1.0min\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time= 1.0min\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.1s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.4s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time= 1.0min\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=  25.2s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  54.2s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  54.3s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=  52.9s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  44.6s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  43.1s\n",
      "[CV] END regressor__max_depth=30, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=  42.8s\n",
      "Best parameters: {'regressor__max_depth': 30, 'regressor__min_samples_leaf': 1, 'regressor__n_estimators': 200}\n",
      "Best CV MAE: 0.021066403486549257\n",
      "Best CV RMSE: 0.030548845863865737\n",
      "Best CV R2: 0.9442009325741738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200],\n",
    "    'regressor__max_depth': [10, 20, 30],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring={\n",
    "        'MAE': 'neg_mean_absolute_error',\n",
    "        'RMSE': 'neg_root_mean_squared_error',\n",
    "        'R2': 'r2'\n",
    "    },\n",
    "    refit='MAE',  # Use MAE to choose the best model\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Split your data\n",
    "X = df_sample.drop(columns=['resale_price'])\n",
    "y = df_sample['resale_price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV MAE:\", -grid_search.cv_results_['mean_test_MAE'][grid_search.best_index_])\n",
    "print(\"Best CV RMSE:\", -grid_search.cv_results_['mean_test_RMSE'][grid_search.best_index_])\n",
    "print(\"Best CV R2:\", grid_search.cv_results_['mean_test_R2'][grid_search.best_index_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c01ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(\n",
    "        max_depth=30,\n",
    "        min_samples_leaf=1,\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a34053e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "X_full = df_normalized_clean.drop(columns=['resale_price'])\n",
    "y_full = df_normalized_clean['resale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa84429",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(X_full, y_full)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model.fit(X_full, y_full)\n",
    "#joblib.dump(best_model, 'best_resale_price_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b6b8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "# Define custom RMSE scorer\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def safe_mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "# Scoring dictionary\n",
    "scoring = {\n",
    "    'r2': 'r2',\n",
    "    'mae': make_scorer(mean_absolute_error),\n",
    "    'rmse': make_scorer(rmse),\n",
    "    'mape': make_scorer(safe_mape)\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 5-Fold CV\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c11416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R²:   0.9670\n",
      "Average MAE:  0.0164\n",
      "Average RMSE: 0.0235\n",
      "Average MAPE: 6.7128\n"
     ]
    }
   ],
   "source": [
    "# Run cross-validation\n",
    "cv_results = cross_validate(best_model, X_train, y_train, scoring=scoring, cv=cv)\n",
    "\n",
    "# Print average scores\n",
    "print(f\"Average R²:   {np.mean(cv_results['test_r2']):.4f}\")\n",
    "print(f\"Average MAE:  {np.mean(cv_results['test_mae']):.4f}\")\n",
    "print(f\"Average RMSE: {np.mean(cv_results['test_rmse']):.4f}\")\n",
    "print(f\"Average MAPE: {np.mean(cv_results['test_mape']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05fb65a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Final Evaluation on Held-Out Test Set:\n",
      "  R²:   0.9681\n",
      "  MAE:  0.0161\n",
      "  RMSE: 0.0230\n",
      "  MAPE: 6.4150\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n🧪 Final Evaluation on Held-Out Test Set:\")\n",
    "print(f\"  R²:   {r2_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"  MAE:  {mean_absolute_error(y_test, y_pred_test):.4f}\")\n",
    "print(f\"  RMSE: {rmse(y_test, y_pred_test):.4f}\")\n",
    "print(f\"  MAPE: {safe_mape(y_test, y_pred_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495b1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel = joblib.load('/Users/erica/Desktop/Y3S2/DSE3101/Local/best_resale_price_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ba694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocessor': ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                 ['storey_range', 'remaining_lease', 'lat',\n",
      "                                  'lon', 'nearest_mrt_distance',\n",
      "                                  'nearest_bus_distance', 'education_score',\n",
      "                                  'shopping_score', 'food_score',\n",
      "                                  'recreation_score', 'healthcare_score',\n",
      "                                  'inflation_rate (x100)',\n",
      "                                  'resident_unemployment_rate', 'interest_rate',\n",
      "                                  'avg_household_income', 'priv_prop',\n",
      "                                  'flat_type', 'year', 'month_num',\n",
      "                                  'NoReligion', 'Buddhism', 'Taoism1', 'Islam',\n",
      "                                  'Hinduism', 'Sikhism',\n",
      "                                  'Christianity_Catholic',\n",
      "                                  'Christianity_OtherChristians',\n",
      "                                  'OtherReligions']),\n",
      "                                ('cat', OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['town'])]), 'regressor': RandomForestRegressor(max_depth=30, n_estimators=200, random_state=42)}\n"
     ]
    }
   ],
   "source": [
    "print(bestmodel.named_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1de2f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              feature  importance\n",
      "16                     num__flat_type    0.455028\n",
      "1                num__remaining_lease    0.137592\n",
      "8                     num__food_score    0.104805\n",
      "19                    num__NoReligion    0.059625\n",
      "17                          num__year    0.037338\n",
      "26  num__Christianity_OtherChristians    0.032084\n",
      "2                            num__lat    0.030482\n",
      "0                   num__storey_range    0.025742\n",
      "20                      num__Buddhism    0.016226\n",
      "4           num__nearest_mrt_distance    0.015881\n",
      "3                            num__lon    0.014628\n",
      "9               num__recreation_score    0.010955\n",
      "10              num__healthcare_score    0.009691\n",
      "7                 num__shopping_score    0.007427\n",
      "6                num__education_score    0.005813\n",
      "13                 num__interest_rate    0.005541\n",
      "25         num__Christianity_Catholic    0.003776\n",
      "35             cat__town_CENTRAL AREA    0.003488\n",
      "5           num__nearest_bus_distance    0.003128\n",
      "15                     num__priv_prop    0.003115\n",
      "11         num__inflation_rate (x100)    0.002595\n",
      "14          num__avg_household_income    0.002544\n",
      "18                     num__month_num    0.002440\n",
      "22                         num__Islam    0.002364\n",
      "23                      num__Hinduism    0.001893\n",
      "12    num__resident_unemployment_rate    0.001546\n",
      "27                num__OtherReligions    0.001058\n",
      "21                       num__Taoism1    0.000769\n",
      "24                       num__Sikhism    0.000731\n",
      "42          cat__town_KALLANG/WHAMPOA    0.000425\n",
      "40              cat__town_JURONG EAST    0.000280\n",
      "31              cat__town_BUKIT BATOK    0.000209\n",
      "53                   cat__town_YISHUN    0.000126\n",
      "51                cat__town_TOA PAYOH    0.000090\n",
      "47                cat__town_SEMBAWANG    0.000074\n",
      "48                 cat__town_SENGKANG    0.000063\n",
      "46               cat__town_QUEENSTOWN    0.000059\n",
      "29                    cat__town_BEDOK    0.000053\n",
      "39                  cat__town_HOUGANG    0.000050\n",
      "33            cat__town_BUKIT PANJANG    0.000041\n",
      "38                  cat__town_GEYLANG    0.000032\n",
      "37                 cat__town_CLEMENTI    0.000026\n",
      "28               cat__town_ANG MO KIO    0.000025\n",
      "36            cat__town_CHOA CHU KANG    0.000022\n",
      "30                   cat__town_BISHAN    0.000021\n",
      "32              cat__town_BUKIT MERAH    0.000021\n",
      "50                 cat__town_TAMPINES    0.000019\n",
      "41              cat__town_JURONG WEST    0.000011\n",
      "34              cat__town_BUKIT TIMAH    0.000011\n",
      "49                cat__town_SERANGOON    0.000011\n",
      "45                  cat__town_PUNGGOL    0.000010\n",
      "52                cat__town_WOODLANDS    0.000010\n",
      "44                cat__town_PASIR RIS    0.000007\n",
      "43            cat__town_MARINE PARADE    0.000001\n"
     ]
    }
   ],
   "source": [
    "importances = bestmodel.named_steps['regressor'].feature_importances_\n",
    "\n",
    "# If using column transformer in the preprocessor:\n",
    "feature_names = bestmodel.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "import pandas as pd\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(importance_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
