{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Point, shape\n",
    "import requests\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from math import radians, cos, sin, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"../data/cleaned/resale_price_clean_final.csv.zip\", 'r') as zip_ref:\n",
    "    file_name = zip_ref.namelist()[0] \n",
    "    with zip_ref.open(file_name) as file:\n",
    "        df_resale = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each column, store the max and min for later normalization\n",
    "min_max_dict = {\n",
    "    col: {\n",
    "        \"min\": df_resale[col].min(),\n",
    "        \"max\": df_resale[col].max()\n",
    "    }\n",
    "    for col in df_resale.columns\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONEMAP_TOKEN = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiI1M2M4NGU0YmJlMWVlZDhmMDczNDk4ODVmZDExYWRjOSIsImlzcyI6Imh0dHA6Ly9pbnRlcm5hbC1hbGItb20tcHJkZXppdC1pdC1uZXctMTYzMzc5OTU0Mi5hcC1zb3V0aGVhc3QtMS5lbGIuYW1hem9uYXdzLmNvbS9hcGkvdjIvdXNlci9wYXNzd29yZCIsImlhdCI6MTc0Mzc1ODAyNSwiZXhwIjoxNzQ0MDE3MjI1LCJuYmYiOjE3NDM3NTgwMjUsImp0aSI6IkF6YWZjWGxDb2tNb0hmQ1AiLCJ1c2VyX2lkIjozNTA0LCJmb3JldmVyIjpmYWxzZX0.CMD124pML3xaJU45AklBASBYNmojp_wctKoRupiDkQ0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Planning area\n",
    "# def load_planning_area_polygons():\n",
    "#     url = \"https://www.onemap.gov.sg/api/public/popapi/getAllPlanningarea?year=2024\"\n",
    "#     headers = {\"Authorization\": ONEMAP_TOKEN}\n",
    "#     response = requests.get(url,headers=headers)\n",
    "#     return response.json()\n",
    "\n",
    "# planning_area = load_planning_area_polygons()\n",
    "# with open('../data/raw/planning_area.json', 'w') as f:\n",
    "#     json.dump(planning_area, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/planning_area.json') as f:\n",
    "    planning_areas = json.load(f)['SearchResults']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_from_postal(postal_code):\n",
    "    url = f\"https://www.onemap.gov.sg/api/common/elastic/search?searchVal={postal_code}&returnGeom=Y&getAddrDetails=Y&pageNum=1\"\n",
    "    headers = {\"Authorization\": ONEMAP_TOKEN}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    if data[\"found\"] > 0:\n",
    "        result = data[\"results\"][0]\n",
    "        return float(result[\"LATITUDE\"]), float(result[\"LONGITUDE\"])\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def get_planning_area_from_point(lat, lon, planning_areas):\n",
    "    point = Point(lon, lat) \n",
    "    \n",
    "    for area in planning_areas:\n",
    "        geojson = json.loads(area['geojson'])  \n",
    "        polygon = shape(geojson)\n",
    "        \n",
    "        if polygon.contains(point):\n",
    "            return area['pln_area_n']\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_planning_area_from_postal(postal_code):\n",
    "    lat, lon = get_coordinates_from_postal(postal_code)\n",
    "    if (lat is None) or (lon is None):\n",
    "        return \"Invalid postal code\"\n",
    "    return get_planning_area_from_point(lat, lon, planning_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stops = gpd.read_file(\"../data/raw/BusStopLocation_Nov2024/BusStop.shp\")\n",
    "MRT_stops = pd.read_csv(\"../data/raw/MRT Stations.csv\")\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # radius of Earth in meters\n",
    "    phi1, phi2 = radians(lat1), radians(lat2)\n",
    "    dphi = radians(lat2 - lat1)\n",
    "    dlambda = radians(lon2 - lon1)\n",
    "    a = sin(dphi/2)**2 + cos(phi1)*cos(phi2)*sin(dlambda/2)**2\n",
    "    return 2*R*atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "from pyproj import Transformer\n",
    "\n",
    "transformer = Transformer.from_crs(\"EPSG:3414\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "def svy21_to_wgs84(easting, northing):\n",
    "    lon, lat = transformer.transform(easting, northing)\n",
    "    return lat, lon\n",
    "\n",
    "\n",
    "bus_stops['x_coord'] = bus_stops.geometry.apply(lambda geom: geom.x)\n",
    "bus_stops['y_coord'] = bus_stops.geometry.apply(lambda geom: geom.y)\n",
    "bus_stops['Latitude'], bus_stops['Longitude'] = zip(*bus_stops.apply(lambda row: svy21_to_wgs84(row['x_coord'], row['y_coord']), axis=1))\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # Radius of Earth in meters\n",
    "    phi1, phi2 = radians(lat1), radians(lat2)\n",
    "    dphi = radians(lat2 - lat1)\n",
    "    dlambda = radians(lon2 - lon1)\n",
    "    a = sin(dphi/2)**2 + cos(phi1)*cos(phi2)*sin(dlambda/2)**2\n",
    "    return 2 * R * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "def get_nearest_distances(lat, lon):\n",
    "    MRT_stops['distance'] = MRT_stops.apply(\n",
    "        lambda row: haversine(lat, lon, row['Latitude'], row['Longitude']), axis=1\n",
    "    )\n",
    "    nearest_mrt_distance = MRT_stops['distance'].min()\n",
    "\n",
    "    # Calculate distances to all bus stops\n",
    "    bus_stops['distance'] = bus_stops.apply(\n",
    "        lambda row: haversine(lat, lon, row['Latitude'], row['Longitude']), axis=1\n",
    "    )\n",
    "    nearest_bus_distance = bus_stops['distance'].min()\n",
    "\n",
    "    return nearest_mrt_distance, nearest_bus_distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(value, col):\n",
    "    min_val = min_max_dict[col][\"min\"]\n",
    "    max_val = min_max_dict[col][\"max\"]\n",
    "    if max_val == min_val:\n",
    "        return 0 \n",
    "    return (value - min_val) / (max_val - min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_predict(storey_range, floor_area, remaining_lease, postal_code, model):\n",

    "    town = get_planning_area_from_postal(postal_code)\n",
    "    lat, lon = get_coordinates_from_postal(postal_code)\n",

    "    # town, lat, lon\n",
    "    town = get_planning_area_from_postal(postal_code)\n",
    "    lat, lon = get_coordinates_from_postal(postal_code)\n",
    "\n",
    "    ########\n",
    "\n",
    "    ########\n",
    "\n",

    "    X_input = pd.DataFrame([{\n",
    "        'town': town,\n",
    "        'storey_range': storey_range,\n",
    "        'floor_area_sqm': floor_area,\n",
    "        'remaining_lease': remaining_lease,\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'nearest_mrt_distance': get_nearest_distances(lat,lon)[0],\n",
    "        'nearest_bus_distance': get_nearest_distances(lat,lon)[1],\n",
    "        'education_score': ,\n",
    "        'shopping_score': ,\n",
    "        'food_score': ,\n",
    "        'recreation_score': ,\n",
    "        'healthcare_score': ,\n",
    "\n",
    "        # Based on 2024-12 data\n",
    "        'inflation_rate (x100)': 0.3468,\n",
    "        'resident_unemployment_rate': 2.0,\n",
    "        'interest_rate': 2.1123,\n",

    "        'fx_rate': 1.3503,\n",


    "\n",
    "        'avg_household_income': ,\n",
    "        'NoReligion': ,\n",
    "        'Buddhism':,\n",
    "        'Taoism1': ,\n",
    "        'Islam': ,\n",
    "        'Hinduism': ,\n",
    "        'Sikhism': ,\n",
    "        'Christianity_Catholic': ,\n",
    "        'Christianity_OtherChristians': ,\n",
    "        'OtherReligions': ,\n",

    "        'Chinese': ,\n",
    "        'Malays': ,\n",
    "        'Indians': ,\n",
    "        'Others': ,\n",
    "        'priv_prop': ,\n",

    "        'priv_prop': , # ??\n",

    "        'year': 2025,\n",
    "        'month_num': 4\n",
    "        }])\n",
    "    \n",
    "    # for each input, make them normalized by using their (original value - min)/(max - min)\n",
    "    for col in X_input.columns:\n",
    "        if col in min_max_dict:\n",
    "            X_input[col] = X_input[col].apply(lambda x: normalize_column(x, col))\n",
    "\n",
    "    return model.predict(X_input)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
