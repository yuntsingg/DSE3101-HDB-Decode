{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Point, shape\n",
    "import requests\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from math import radians, cos, sin, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"../data/cleaned/resale_price_clean_final.csv.zip\", 'r') as zip_ref:\n",
    "    file_name = zip_ref.namelist()[0] \n",
    "    with zip_ref.open(file_name) as file:\n",
    "        df_resale = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each column, store the max and min for later normalization\n",
    "min_max_dict = {\n",
    "    col: {\n",
    "        \"min\": df_resale[col].min(),\n",
    "        \"max\": df_resale[col].max()\n",
    "    }\n",
    "    for col in df_resale.columns\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(value, col):\n",
    "    min_val = min_max_dict[col][\"min\"]\n",
    "    max_val = min_max_dict[col][\"max\"]\n",
    "    if max_val == min_val:\n",
    "        return 0 \n",
    "    return (value - min_val) / (max_val - min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONEMAP_TOKEN = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiI1M2M4NGU0YmJlMWVlZDhmMDczNDk4ODVmZDExYWRjOSIsImlzcyI6Imh0dHA6Ly9pbnRlcm5hbC1hbGItb20tcHJkZXppdC1pdC1uZXctMTYzMzc5OTU0Mi5hcC1zb3V0aGVhc3QtMS5lbGIuYW1hem9uYXdzLmNvbS9hcGkvdjIvdXNlci9wYXNzd29yZCIsImlhdCI6MTc0Mzc1ODAyNSwiZXhwIjoxNzQ0MDE3MjI1LCJuYmYiOjE3NDM3NTgwMjUsImp0aSI6IkF6YWZjWGxDb2tNb0hmQ1AiLCJ1c2VyX2lkIjozNTA0LCJmb3JldmVyIjpmYWxzZX0.CMD124pML3xaJU45AklBASBYNmojp_wctKoRupiDkQ0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get town, lat, lon, MRT, bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Planning area\n",
    "# def load_planning_area_polygons():\n",
    "#     url = \"https://www.onemap.gov.sg/api/public/popapi/getAllPlanningarea?year=2024\"\n",
    "#     headers = {\"Authorization\": ONEMAP_TOKEN}\n",
    "#     response = requests.get(url,headers=headers)\n",
    "#     return response.json()\n",
    "\n",
    "# planning_area = load_planning_area_polygons()\n",
    "# with open('../data/raw/planning_area.json', 'w') as f:\n",
    "#     json.dump(planning_area, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/planning_area.json') as f:\n",
    "    planning_areas = json.load(f)['SearchResults']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_from_postal(postal_code):\n",
    "    url = f\"https://www.onemap.gov.sg/api/common/elastic/search?searchVal={postal_code}&returnGeom=Y&getAddrDetails=Y&pageNum=1\"\n",
    "    headers = {\"Authorization\": ONEMAP_TOKEN}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    if data[\"found\"] > 0:\n",
    "        result = data[\"results\"][0]\n",
    "        return float(result[\"LATITUDE\"]), float(result[\"LONGITUDE\"])\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def get_planning_area_from_point(lat, lon, planning_areas):\n",
    "    point = Point(lon, lat) \n",
    "    \n",
    "    for area in planning_areas:\n",
    "        geojson = json.loads(area['geojson'])  \n",
    "        polygon = shape(geojson)\n",
    "        \n",
    "        if polygon.contains(point):\n",
    "            return area['pln_area_n']\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_planning_area_from_postal(postal_code):\n",
    "    lat, lon = get_coordinates_from_postal(postal_code)\n",
    "    if (lat is None) or (lon is None):\n",
    "        return \"Invalid postal code\"\n",
    "    return get_planning_area_from_point(lat, lon, planning_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stops = gpd.read_file(\"../data/raw/BusStopLocation_Nov2024/BusStop.shp\")\n",
    "MRT_stops = pd.read_csv(\"../data/raw/MRT Stations.csv\")\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # radius of Earth in meters\n",
    "    phi1, phi2 = radians(lat1), radians(lat2)\n",
    "    dphi = radians(lat2 - lat1)\n",
    "    dlambda = radians(lon2 - lon1)\n",
    "    a = sin(dphi/2)**2 + cos(phi1)*cos(phi2)*sin(dlambda/2)**2\n",
    "    return 2*R*atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "from pyproj import Transformer\n",
    "\n",
    "transformer = Transformer.from_crs(\"EPSG:3414\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "def svy21_to_wgs84(easting, northing):\n",
    "    lon, lat = transformer.transform(easting, northing)\n",
    "    return lat, lon\n",
    "\n",
    "\n",
    "bus_stops['x_coord'] = bus_stops.geometry.apply(lambda geom: geom.x)\n",
    "bus_stops['y_coord'] = bus_stops.geometry.apply(lambda geom: geom.y)\n",
    "bus_stops['Latitude'], bus_stops['Longitude'] = zip(*bus_stops.apply(lambda row: svy21_to_wgs84(row['x_coord'], row['y_coord']), axis=1))\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # Radius of Earth in meters\n",
    "    phi1, phi2 = radians(lat1), radians(lat2)\n",
    "    dphi = radians(lat2 - lat1)\n",
    "    dlambda = radians(lon2 - lon1)\n",
    "    a = sin(dphi/2)**2 + cos(phi1)*cos(phi2)*sin(dlambda/2)**2\n",
    "    return 2 * R * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "def get_nearest_distances(lat, lon):\n",
    "    MRT_stops['distance'] = MRT_stops.apply(\n",
    "        lambda row: haversine(lat, lon, row['Latitude'], row['Longitude']), axis=1\n",
    "    )\n",
    "    nearest_mrt_distance = MRT_stops['distance'].min()\n",
    "\n",
    "    # Calculate distances to all bus stops\n",
    "    bus_stops['distance'] = bus_stops.apply(\n",
    "        lambda row: haversine(lat, lon, row['Latitude'], row['Longitude']), axis=1\n",
    "    )\n",
    "    nearest_bus_distance = bus_stops['distance'].min()\n",
    "\n",
    "    return nearest_mrt_distance, nearest_bus_distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get amenity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amenity_score(hdb_lat, hdb_lon, amenity_type):\n",
    " \n",
    "    if amenity_type == \"education\":\n",
    "        df = pd.read_csv(\"../data/raw/Amenities_school.csv\")\n",
    "    elif amenity_type == \"healthcare\":\n",
    "        df = pd.read_csv(\"../data/raw/Amenities_healthcare.csv\")\n",
    "    elif amenity_type == \"shopping\":\n",
    "        df = pd.read_csv(\"../data/raw/Amenities_shopping.csv\")\n",
    "    elif amenity_type == \"food\":\n",
    "        df = pd.read_csv(\"../data/raw/Amenities_food.csv\")\n",
    "    elif amenity_type == \"recreation\":\n",
    "        df = pd.read_csv(\"../data/raw/Amenities_recreation.csv\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported amenity type: {amenity_type}\")\n",
    "\n",
    "    scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        distance = haversine(hdb_lat, hdb_lon, row['lat'], row['lon'])\n",
    "        if distance <= 3000:\n",
    "            score = 1 * 1000 / (distance + 50)\n",
    "            scores.append(score)\n",
    "    \n",
    "    total_score = sum(scores)\n",
    "\n",
    "    return total_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get religion, avg household income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demographic (town):\n",
    "    # religion\n",
    "    df_religion = pd.read_csv(\"../data/raw/religion_2020.csv\")\n",
    "    df_religion.rename(columns = {\"Number\":\"town\"}, inplace = True)\n",
    "    df_religion['town'] = df_religion['town'].replace('Kallang', 'Kallang/Whampoa')\n",
    "    # Combine 'Outram', 'Downtown Core', 'River Valley', 'Novena' into 'Central Area'\n",
    "    central_area_row = df_religion[df_religion['town'].isin(['Outram', 'Downtown Core', 'River Valley', 'Novena'])].sum(numeric_only=True)\n",
    "    central_area_row['town'] = 'CENTRAL AREA'\n",
    "    df_religion = df_religion[~df_religion['town'].isin(['Outram', 'Downtown Core', 'River Valley', 'Novena', 'Total','Others'])]\n",
    "    df_religion = pd.concat([df_religion, pd.DataFrame([central_area_row])], ignore_index=True)\n",
    "    # Capitalize the 'town' column\n",
    "    df_religion['town'] = df_religion['town'].str.upper()\n",
    "\n",
    "    for col in df_religion.columns:\n",
    "        if col != \"town\":\n",
    "            df_religion[col] = pd.to_numeric(df_religion[col], errors='coerce')\n",
    "            df_religion[col] = df_religion[col].astype(float)\n",
    "    for col in df_religion.columns:\n",
    "        if col != \"town\" and col != \"Total\":\n",
    "            df_religion[col] = df_religion[col] / df_religion[\"Total\"]\n",
    "\n",
    "    # avg household income\n",
    "    df_income = pd.read_csv(\"../data/cleaned/resale_price_cleaned.csv\")\n",
    "    df_income = df_income[df_income['month'] == '2024-12']\n",
    "    df_income = df_income[['town', 'avg_household_income']]\n",
    "    df_income = df_income.drop_duplicates()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for _, row in df_religion.iterrows():\n",
    "        if town == row['town']:\n",
    "            df['NoReligion'] = [row['NoReligion']]\n",
    "            df['Buddhism'] = [row['Buddhism']]\n",
    "            df['Taoism1'] = [row['Taoism']]\n",
    "            df['Islam'] = [row['Islam']]\n",
    "            df['Hinduism'] = [row['Hinduism']]\n",
    "            df['Sikhism'] = [row['Sikhism']]\n",
    "            df['Christianity_Catholic'] = [row['Christianity_Catholic']]\n",
    "            df['Christianity_OtherChristians'] = [row['Christianity_OtherChristians']]\n",
    "            df['OtherReligions'] = [row['OtherReligions']]\n",
    "            break\n",
    "    for _, row in df_income.iterrows():\n",
    "        if town == row['town']:\n",
    "            df['avg_household_income'] = [row['avg_household_income']]\n",
    "            break\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26 entries, 109 to 191539\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   town                  26 non-null     object \n",
      " 1   avg_household_income  26 non-null     float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 624.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_income.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_predict(storey_range, floor_area, remaining_lease, postal_code, model):\n",
<<<<<<< HEAD
    "    town = get_planning_area_from_postal(postal_code)\n",
    "    lat, lon = get_coordinates_from_postal(postal_code)\n",
=======
    "    # town, lat, lon\n",
    "    town = get_planning_area_from_postal(postal_code)\n",
    "    lat, lon = get_coordinates_from_postal(postal_code)\n",
    "\n",
    "    # amenity score\n",
    "    education_score = get_amenity_score(lat, lon, \"education\")\n",
    "    shopping_score = get_amenity_score(lat, lon, \"shopping\")\n",
    "    food_score = get_amenity_score(lat, lon, \"food\")\n",
    "    recreation_score = get_amenity_score(lat, lon, \"recreation\")\n",
    "    healthcare_score = get_amenity_score(lat, lon, \"healthcare\")\n",
    "\n",
    "    # demographic\n",
    "    demographic_df = get_demographic(town)\n",
    "\n",
>>>>>>> 3526e5de3d940592f0e40b9e3ad8c194929878e0
    "    X_input = pd.DataFrame([{\n",
    "        'town': town,\n",
    "        'storey_range': storey_range,\n",
    "        'floor_area_sqm': floor_area,\n",
    "        'remaining_lease': remaining_lease,\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'nearest_mrt_distance': get_nearest_distances(lat,lon)[0],\n",
    "        'nearest_bus_distance': get_nearest_distances(lat,lon)[1],\n",
    "        'education_score': education_score,\n",
    "        'shopping_score': shopping_score,\n",
    "        'food_score': food_score,\n",
    "        'recreation_score': recreation_score,\n",
    "        'healthcare_score': healthcare_score,\n",
    "\n",
    "        # Based on 2024-12 data\n",
    "        'inflation_rate (x100)': 0.3468,\n",
    "        'resident_unemployment_rate': 2.0,\n",
    "        'interest_rate': 2.1123,\n",
<<<<<<< HEAD
    "        \n",
    "        'avg_household_income': demographic_df['avg_household_income'].iloc[0],\n",
    "        'NoReligion': demographic_df['NoReligion'].iloc[0],\n",
    "        'Buddhism': demographic_df['Buddhism'].iloc[0],\n",
    "        'Taoism1': demographic_df['Taoism1'].iloc[0],\n",
    "        'Islam': demographic_df['Islam'].iloc[0],\n",
    "        'Hinduism': demographic_df['Hinduism'].iloc[0],\n",
    "        'Sikhism': demographic_df['Sikhism'].iloc[0],\n",
    "        'Christianity_Catholic': demographic_df['Christianity_Catholic'].iloc[0],\n",
    "        'Christianity_OtherChristians': demographic_df['Christianity_OtherChristians'].iloc[0],\n",
    "        'OtherReligions': demographic_df['OtherReligions'].iloc[0],\n",
    "        'priv_prop': ,\n",
    "        \n",
=======
<<<<<<< HEAD
    "        'fx_rate': 1.3503,\n",
=======
>>>>>>> 3526e5de3d940592f0e40b9e3ad8c194929878e0
    "\n",
    "        'avg_household_income': ,\n",
    "        'NoReligion': ,\n",
    "        'Buddhism':,\n",
    "        'Taoism1': ,\n",
    "        'Islam': ,\n",
    "        'Hinduism': ,\n",
    "        'Sikhism': ,\n",
    "        'Christianity_Catholic': ,\n",
    "        'Christianity_OtherChristians': ,\n",
    "        'OtherReligions': ,\n",
<<<<<<< HEAD
    "        'Chinese': ,\n",
    "        'Malays': ,\n",
    "        'Indians': ,\n",
    "        'Others': ,\n",
    "        'priv_prop': ,\n",
=======
    "        'priv_prop': , # ??\n",
>>>>>>> 3526e5de3d940592f0e40b9e3ad8c194929878e0
>>>>>>> 277a08e73811d369f2411056945a30e6868f9804
    "        'year': 2025,\n",
    "        'month_num': 4\n",
    "        }])\n",
    "    \n",
    "    # for each input, make them normalized by using their (original value - min)/(max - min)\n",
    "    for col in X_input.columns:\n",
    "        if col in min_max_dict:\n",
    "            X_input[col] = X_input[col].apply(lambda x: normalize_column(x, col))\n",
    "\n",
    "    return model.predict(X_input)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
